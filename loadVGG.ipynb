{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "#from utee import misc, quant, selector\n",
    "\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Load CIFAR-10\n",
    "NUM_TRAIN = 49000\n",
    "\n",
    "# The torchvision.transforms package provides tools for preprocessing data\n",
    "# and for performing data augmentation; here we set up a transform to\n",
    "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
    "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
    "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
    "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
    "# training set into train and val sets by passing a Sampler object to the\n",
    "# DataLoader telling how it should sample from the underlying Dataset.\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    t_begin = time.time()\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                t_elapse = time.time() - t_begin\n",
    "                print('Elapsed %.4f s, Epoch %d,  Iteration %d, loss = %.4f' % (t_elapse, e, t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features.0.weight', 'features.0.bias', 'features.2.weight', 'features.2.bias', 'features.5.weight', 'features.5.bias', 'features.7.weight', 'features.7.bias', 'features.10.weight', 'features.10.bias', 'features.12.weight', 'features.12.bias', 'features.14.weight', 'features.14.bias', 'features.16.weight', 'features.16.bias', 'features.19.weight', 'features.19.bias', 'features.21.weight', 'features.21.bias', 'features.23.weight', 'features.23.bias', 'features.25.weight', 'features.25.bias', 'features.28.weight', 'features.28.bias', 'features.30.weight', 'features.30.bias', 'features.32.weight', 'features.32.bias', 'features.34.weight', 'features.34.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Model.vgg_modules import *\n",
    "\n",
    "VGG19 = vgg19()\n",
    "VGG19.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../pretrain_model/model_best.pth.tar'\n",
    "VGG19.features = torch.nn.DataParallel(VGG19.features)\n",
    "VGG19.cuda()\n",
    "checkpoint = torch.load(PATH)\n",
    "start_epoch = checkpoint['epoch']\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "#print(VGG19.state_dict().keys())\n",
    "#print(checkpoint['state_dict'].keys())\n",
    "VGG19.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FixedVGG(\n",
       "  (features): Sequential(\n",
       "    (Q0): activation_quantization()\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (Q2): activation_quantization()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Q5): activation_quantization()\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (Q7): activation_quantization()\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Q10): activation_quantization()\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (Q12): activation_quantization()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (Q14): activation_quantization()\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (Q16): activation_quantization()\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Q19): activation_quantization()\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (Q21): activation_quantization()\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (Q23): activation_quantization()\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace)\n",
       "    (Q25): activation_quantization()\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Q28): activation_quantization()\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (Q30): activation_quantization()\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace)\n",
       "    (Q32): activation_quantization()\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace)\n",
       "    (Q34): activation_quantization()\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (Q1): activation_quantization()\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (Q2): activation_quantization()\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (Q3): activation_quantization()\n",
       "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Model.Fixedvgg import *\n",
    "\n",
    "FixedVGG19 = fixed_vgg19()\n",
    "FixedVGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../pretrain_model/model_best.pth.tar'\n",
    "FixedVGG19.features = torch.nn.DataParallel(FixedVGG19.features)\n",
    "FixedVGG19.cuda()\n",
    "checkpoint = torch.load(PATH)\n",
    "start_epoch = checkpoint['epoch']\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "#print(VGG19.state_dict().keys())\n",
    "#print(checkpoint['state_dict'].keys())\n",
    "FixedVGG19.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed VGG11 Accuracy:\n",
      "Checking accuracy on test set\n",
      "Got 1000 / 10000 correct (10.00)\n",
      "\n",
      "Floadt VGG11 Accuracy:\n",
      "Checking accuracy on test set\n",
      "Got 9206 / 10000 correct (92.06)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFixed VGG11 Accuracy:\")\n",
    "check_accuracy_part34(loader_test, FixedVGG19)\n",
    "print(\"\\nFloadt VGG11 Accuracy:\")\n",
    "check_accuracy_part34(loader_test, VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed 0.0916 s, Epoch 0,  Iteration 0, loss = 0.0071\n",
      "Checking accuracy on validation set\n",
      "Got 981 / 1000 correct (98.10)\n",
      "\n",
      "Elapsed 16.5861 s, Epoch 0,  Iteration 100, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 986 / 1000 correct (98.60)\n",
      "\n",
      "Elapsed 32.9692 s, Epoch 0,  Iteration 200, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 987 / 1000 correct (98.70)\n",
      "\n",
      "Elapsed 49.2484 s, Epoch 0,  Iteration 300, loss = 0.0018\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 65.5877 s, Epoch 0,  Iteration 400, loss = 0.0002\n",
      "Checking accuracy on validation set\n",
      "Got 988 / 1000 correct (98.80)\n",
      "\n",
      "Elapsed 81.8999 s, Epoch 0,  Iteration 500, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 985 / 1000 correct (98.50)\n",
      "\n",
      "Elapsed 98.2306 s, Epoch 0,  Iteration 600, loss = 0.0008\n",
      "Checking accuracy on validation set\n",
      "Got 986 / 1000 correct (98.60)\n",
      "\n",
      "Elapsed 114.5696 s, Epoch 0,  Iteration 700, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 986 / 1000 correct (98.60)\n",
      "\n",
      "Elapsed 125.7458 s, Epoch 1,  Iteration 0, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 991 / 1000 correct (99.10)\n",
      "\n",
      "Elapsed 142.0650 s, Epoch 1,  Iteration 100, loss = 0.0006\n",
      "Checking accuracy on validation set\n",
      "Got 989 / 1000 correct (98.90)\n",
      "\n",
      "Elapsed 158.3907 s, Epoch 1,  Iteration 200, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 992 / 1000 correct (99.20)\n",
      "\n",
      "Elapsed 174.7146 s, Epoch 1,  Iteration 300, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 992 / 1000 correct (99.20)\n",
      "\n",
      "Elapsed 191.0418 s, Epoch 1,  Iteration 400, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 988 / 1000 correct (98.80)\n",
      "\n",
      "Elapsed 207.3546 s, Epoch 1,  Iteration 500, loss = 0.0003\n",
      "Checking accuracy on validation set\n",
      "Got 989 / 1000 correct (98.90)\n",
      "\n",
      "Elapsed 223.6683 s, Epoch 1,  Iteration 600, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 239.9682 s, Epoch 1,  Iteration 700, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 987 / 1000 correct (98.70)\n",
      "\n",
      "Elapsed 251.1396 s, Epoch 2,  Iteration 0, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 987 / 1000 correct (98.70)\n",
      "\n",
      "Elapsed 267.4710 s, Epoch 2,  Iteration 100, loss = 0.0002\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 283.7638 s, Epoch 2,  Iteration 200, loss = 0.0006\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 300.0407 s, Epoch 2,  Iteration 300, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 316.3862 s, Epoch 2,  Iteration 400, loss = 0.0222\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 332.7331 s, Epoch 2,  Iteration 500, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 988 / 1000 correct (98.80)\n",
      "\n",
      "Elapsed 349.0606 s, Epoch 2,  Iteration 600, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 989 / 1000 correct (98.90)\n",
      "\n",
      "Elapsed 365.3879 s, Epoch 2,  Iteration 700, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 376.5310 s, Epoch 3,  Iteration 0, loss = 0.0003\n",
      "Checking accuracy on validation set\n",
      "Got 991 / 1000 correct (99.10)\n",
      "\n",
      "Elapsed 392.9406 s, Epoch 3,  Iteration 100, loss = 0.0014\n",
      "Checking accuracy on validation set\n",
      "Got 992 / 1000 correct (99.20)\n",
      "\n",
      "Elapsed 409.2290 s, Epoch 3,  Iteration 200, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 989 / 1000 correct (98.90)\n",
      "\n",
      "Elapsed 425.5262 s, Epoch 3,  Iteration 300, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 993 / 1000 correct (99.30)\n",
      "\n",
      "Elapsed 441.8456 s, Epoch 3,  Iteration 400, loss = 0.0003\n",
      "Checking accuracy on validation set\n",
      "Got 986 / 1000 correct (98.60)\n",
      "\n",
      "Elapsed 458.2139 s, Epoch 3,  Iteration 500, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 987 / 1000 correct (98.70)\n",
      "\n",
      "Elapsed 474.6061 s, Epoch 3,  Iteration 600, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 986 / 1000 correct (98.60)\n",
      "\n",
      "Elapsed 490.9566 s, Epoch 3,  Iteration 700, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 986 / 1000 correct (98.60)\n",
      "\n",
      "Elapsed 502.1531 s, Epoch 4,  Iteration 0, loss = 0.0005\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 518.5539 s, Epoch 4,  Iteration 100, loss = 0.0025\n",
      "Checking accuracy on validation set\n",
      "Got 988 / 1000 correct (98.80)\n",
      "\n",
      "Elapsed 535.1132 s, Epoch 4,  Iteration 200, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 551.4976 s, Epoch 4,  Iteration 300, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 987 / 1000 correct (98.70)\n",
      "\n",
      "Elapsed 567.8427 s, Epoch 4,  Iteration 400, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 989 / 1000 correct (98.90)\n",
      "\n",
      "Elapsed 584.1699 s, Epoch 4,  Iteration 500, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 991 / 1000 correct (99.10)\n",
      "\n",
      "Elapsed 600.5188 s, Epoch 4,  Iteration 600, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 988 / 1000 correct (98.80)\n",
      "\n",
      "Elapsed 616.8723 s, Epoch 4,  Iteration 700, loss = 0.0006\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train this model\n",
    "learning_rate = 2e-6\n",
    "\n",
    "optimizer = optim.Adam(params=FixedVGG19.parameters(), lr=learning_rate)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True)\n",
    "train_part34(FixedVGG19, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finetune Fixed VGG11 Accuracy:\n",
      "Checking accuracy on test set\n",
      "Got 9118 / 10000 correct (91.18)\n",
      "\n",
      "Floadt VGG11 Accuracy:\n",
      "Checking accuracy on test set\n",
      "Got 9206 / 10000 correct (92.06)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinetune Fixed VGG11 Accuracy:\")\n",
    "check_accuracy_part34(loader_test, FixedVGG19)\n",
    "print(\"\\nFloadt VGG11 Accuracy:\")\n",
    "check_accuracy_part34(loader_test, VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
