{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "#from utee import misc, quant, selector\n",
    "\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Load CIFAR-10\n",
    "NUM_TRAIN = 49000\n",
    "\n",
    "# The torchvision.transforms package provides tools for preprocessing data\n",
    "# and for performing data augmentation; here we set up a transform to\n",
    "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
    "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
    "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
    "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
    "# training set into train and val sets by passing a Sampler object to the\n",
    "# DataLoader telling how it should sample from the underlying Dataset.\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    t_begin = time.time()\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                t_elapse = time.time() - t_begin\n",
    "                print('Elapsed %.4f s, Epoch %d,  Iteration %d, loss = %.4f' % (t_elapse, e, t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features.0.weight', 'features.0.bias', 'features.2.weight', 'features.2.bias', 'features.5.weight', 'features.5.bias', 'features.7.weight', 'features.7.bias', 'features.10.weight', 'features.10.bias', 'features.12.weight', 'features.12.bias', 'features.14.weight', 'features.14.bias', 'features.16.weight', 'features.16.bias', 'features.19.weight', 'features.19.bias', 'features.21.weight', 'features.21.bias', 'features.23.weight', 'features.23.bias', 'features.25.weight', 'features.25.bias', 'features.28.weight', 'features.28.bias', 'features.30.weight', 'features.30.bias', 'features.32.weight', 'features.32.bias', 'features.34.weight', 'features.34.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Model.vgg_modules import *\n",
    "\n",
    "VGG19 = vgg19()\n",
    "VGG19.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VGG:\n\tMissing key(s) in state_dict: \"features.module.module.0.weight\", \"features.module.module.0.bias\", \"features.module.module.2.weight\", \"features.module.module.2.bias\", \"features.module.module.5.weight\", \"features.module.module.5.bias\", \"features.module.module.7.weight\", \"features.module.module.7.bias\", \"features.module.module.10.weight\", \"features.module.module.10.bias\", \"features.module.module.12.weight\", \"features.module.module.12.bias\", \"features.module.module.14.weight\", \"features.module.module.14.bias\", \"features.module.module.16.weight\", \"features.module.module.16.bias\", \"features.module.module.19.weight\", \"features.module.module.19.bias\", \"features.module.module.21.weight\", \"features.module.module.21.bias\", \"features.module.module.23.weight\", \"features.module.module.23.bias\", \"features.module.module.25.weight\", \"features.module.module.25.bias\", \"features.module.module.28.weight\", \"features.module.module.28.bias\", \"features.module.module.30.weight\", \"features.module.module.30.bias\", \"features.module.module.32.weight\", \"features.module.module.32.bias\", \"features.module.module.34.weight\", \"features.module.module.34.bias\". \n\tUnexpected key(s) in state_dict: \"features.module.0.weight\", \"features.module.0.bias\", \"features.module.2.weight\", \"features.module.2.bias\", \"features.module.5.weight\", \"features.module.5.bias\", \"features.module.7.weight\", \"features.module.7.bias\", \"features.module.10.weight\", \"features.module.10.bias\", \"features.module.12.weight\", \"features.module.12.bias\", \"features.module.14.weight\", \"features.module.14.bias\", \"features.module.16.weight\", \"features.module.16.bias\", \"features.module.19.weight\", \"features.module.19.bias\", \"features.module.21.weight\", \"features.module.21.bias\", \"features.module.23.weight\", \"features.module.23.bias\", \"features.module.25.weight\", \"features.module.25.bias\", \"features.module.28.weight\", \"features.module.28.bias\", \"features.module.30.weight\", \"features.module.30.bias\", \"features.module.32.weight\", \"features.module.32.bias\", \"features.module.34.weight\", \"features.module.34.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ca6d0613a135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#print(VGG19.state_dict().keys())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#print(checkpoint['state_dict'].keys())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mVGG19\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 721\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VGG:\n\tMissing key(s) in state_dict: \"features.module.module.0.weight\", \"features.module.module.0.bias\", \"features.module.module.2.weight\", \"features.module.module.2.bias\", \"features.module.module.5.weight\", \"features.module.module.5.bias\", \"features.module.module.7.weight\", \"features.module.module.7.bias\", \"features.module.module.10.weight\", \"features.module.module.10.bias\", \"features.module.module.12.weight\", \"features.module.module.12.bias\", \"features.module.module.14.weight\", \"features.module.module.14.bias\", \"features.module.module.16.weight\", \"features.module.module.16.bias\", \"features.module.module.19.weight\", \"features.module.module.19.bias\", \"features.module.module.21.weight\", \"features.module.module.21.bias\", \"features.module.module.23.weight\", \"features.module.module.23.bias\", \"features.module.module.25.weight\", \"features.module.module.25.bias\", \"features.module.module.28.weight\", \"features.module.module.28.bias\", \"features.module.module.30.weight\", \"features.module.module.30.bias\", \"features.module.module.32.weight\", \"features.module.module.32.bias\", \"features.module.module.34.weight\", \"features.module.module.34.bias\". \n\tUnexpected key(s) in state_dict: \"features.module.0.weight\", \"features.module.0.bias\", \"features.module.2.weight\", \"features.module.2.bias\", \"features.module.5.weight\", \"features.module.5.bias\", \"features.module.7.weight\", \"features.module.7.bias\", \"features.module.10.weight\", \"features.module.10.bias\", \"features.module.12.weight\", \"features.module.12.bias\", \"features.module.14.weight\", \"features.module.14.bias\", \"features.module.16.weight\", \"features.module.16.bias\", \"features.module.19.weight\", \"features.module.19.bias\", \"features.module.21.weight\", \"features.module.21.bias\", \"features.module.23.weight\", \"features.module.23.bias\", \"features.module.25.weight\", \"features.module.25.bias\", \"features.module.28.weight\", \"features.module.28.bias\", \"features.module.30.weight\", \"features.module.30.bias\", \"features.module.32.weight\", \"features.module.32.bias\", \"features.module.34.weight\", \"features.module.34.bias\". "
     ]
    }
   ],
   "source": [
    "PATH = '../pretrain_model/model_best.pth.tar'\n",
    "VGG19.features = torch.nn.DataParallel(VGG19.features)\n",
    "VGG19.cuda()\n",
    "checkpoint = torch.load(PATH)\n",
    "start_epoch = checkpoint['epoch']\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "#print(VGG19.state_dict().keys())\n",
    "#print(checkpoint['state_dict'].keys())\n",
    "VGG19.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FixedVGG(\n",
       "  (features): Sequential(\n",
       "    (Q0): activation_quantization()\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (Q2): activation_quantization()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Q5): activation_quantization()\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (Q7): activation_quantization()\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Q10): activation_quantization()\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (Q12): activation_quantization()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (Q14): activation_quantization()\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (Q16): activation_quantization()\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Q19): activation_quantization()\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (Q21): activation_quantization()\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (Q23): activation_quantization()\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace)\n",
       "    (Q25): activation_quantization()\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Q28): activation_quantization()\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (Q30): activation_quantization()\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace)\n",
       "    (Q32): activation_quantization()\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace)\n",
       "    (Q34): activation_quantization()\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (Q1): activation_quantization()\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (Q2): activation_quantization()\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (Q3): activation_quantization()\n",
       "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Model.Fixedvgg import *\n",
    "\n",
    "FixedVGG19 = fixed_vgg19()\n",
    "FixedVGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../pretrain_model/model_best.pth.tar'\n",
    "FixedVGG19.features = torch.nn.DataParallel(FixedVGG19.features)\n",
    "FixedVGG19.cuda()\n",
    "checkpoint = torch.load(PATH)\n",
    "start_epoch = checkpoint['epoch']\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "#print(VGG19.state_dict().keys())\n",
    "#print(checkpoint['state_dict'].keys())\n",
    "FixedVGG19.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed VGG11 Accuracy:\n",
      "Checking accuracy on test set\n",
      "Got 1000 / 10000 correct (10.00)\n",
      "\n",
      "Floadt VGG11 Accuracy:\n",
      "Checking accuracy on test set\n",
      "Got 9206 / 10000 correct (92.06)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFixed VGG11 Accuracy:\")\n",
    "check_accuracy_part34(loader_test, FixedVGG19)\n",
    "print(\"\\nFloadt VGG11 Accuracy:\")\n",
    "check_accuracy_part34(loader_test, VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed 0.0919 s, Epoch 0,  Iteration 0, loss = 0.1974\n",
      "Checking accuracy on validation set\n",
      "Got 890 / 1000 correct (89.00)\n",
      "\n",
      "Elapsed 16.6537 s, Epoch 0,  Iteration 100, loss = 0.0486\n",
      "Checking accuracy on validation set\n",
      "Got 946 / 1000 correct (94.60)\n",
      "\n",
      "Elapsed 33.1723 s, Epoch 0,  Iteration 200, loss = 0.1872\n",
      "Checking accuracy on validation set\n",
      "Got 929 / 1000 correct (92.90)\n",
      "\n",
      "Elapsed 49.7257 s, Epoch 0,  Iteration 300, loss = 0.1135\n",
      "Checking accuracy on validation set\n",
      "Got 930 / 1000 correct (93.00)\n",
      "\n",
      "Elapsed 66.3381 s, Epoch 0,  Iteration 400, loss = 0.4712\n",
      "Checking accuracy on validation set\n",
      "Got 928 / 1000 correct (92.80)\n",
      "\n",
      "Elapsed 82.8642 s, Epoch 0,  Iteration 500, loss = 0.1707\n",
      "Checking accuracy on validation set\n",
      "Got 922 / 1000 correct (92.20)\n",
      "\n",
      "Elapsed 99.4125 s, Epoch 0,  Iteration 600, loss = 0.2294\n",
      "Checking accuracy on validation set\n",
      "Got 906 / 1000 correct (90.60)\n",
      "\n",
      "Elapsed 115.9364 s, Epoch 0,  Iteration 700, loss = 0.2742\n",
      "Checking accuracy on validation set\n",
      "Got 912 / 1000 correct (91.20)\n",
      "\n",
      "Elapsed 127.2683 s, Epoch 1,  Iteration 0, loss = 0.1637\n",
      "Checking accuracy on validation set\n",
      "Got 944 / 1000 correct (94.40)\n",
      "\n",
      "Elapsed 143.8054 s, Epoch 1,  Iteration 100, loss = 0.3030\n",
      "Checking accuracy on validation set\n",
      "Got 795 / 1000 correct (79.50)\n",
      "\n",
      "Elapsed 160.3396 s, Epoch 1,  Iteration 200, loss = 0.7227\n",
      "Checking accuracy on validation set\n",
      "Got 758 / 1000 correct (75.80)\n",
      "\n",
      "Elapsed 176.8767 s, Epoch 1,  Iteration 300, loss = 0.2009\n",
      "Checking accuracy on validation set\n",
      "Got 901 / 1000 correct (90.10)\n",
      "\n",
      "Elapsed 193.3766 s, Epoch 1,  Iteration 400, loss = 0.2782\n",
      "Checking accuracy on validation set\n",
      "Got 924 / 1000 correct (92.40)\n",
      "\n",
      "Elapsed 209.8681 s, Epoch 1,  Iteration 500, loss = 0.0693\n",
      "Checking accuracy on validation set\n",
      "Got 948 / 1000 correct (94.80)\n",
      "\n",
      "Elapsed 226.3671 s, Epoch 1,  Iteration 600, loss = 0.0361\n",
      "Checking accuracy on validation set\n",
      "Got 953 / 1000 correct (95.30)\n",
      "\n",
      "Elapsed 242.8596 s, Epoch 1,  Iteration 700, loss = 0.1937\n",
      "Checking accuracy on validation set\n",
      "Got 953 / 1000 correct (95.30)\n",
      "\n",
      "Elapsed 254.1469 s, Epoch 2,  Iteration 0, loss = 0.2746\n",
      "Checking accuracy on validation set\n",
      "Got 913 / 1000 correct (91.30)\n",
      "\n",
      "Elapsed 270.6973 s, Epoch 2,  Iteration 100, loss = 0.0465\n",
      "Checking accuracy on validation set\n",
      "Got 946 / 1000 correct (94.60)\n",
      "\n",
      "Elapsed 287.2112 s, Epoch 2,  Iteration 200, loss = 0.1036\n",
      "Checking accuracy on validation set\n",
      "Got 936 / 1000 correct (93.60)\n",
      "\n",
      "Elapsed 303.7630 s, Epoch 2,  Iteration 300, loss = 0.1134\n",
      "Checking accuracy on validation set\n",
      "Got 942 / 1000 correct (94.20)\n",
      "\n",
      "Elapsed 320.2768 s, Epoch 2,  Iteration 400, loss = 0.3354\n",
      "Checking accuracy on validation set\n",
      "Got 903 / 1000 correct (90.30)\n",
      "\n",
      "Elapsed 336.7677 s, Epoch 2,  Iteration 500, loss = 0.2749\n",
      "Checking accuracy on validation set\n",
      "Got 947 / 1000 correct (94.70)\n",
      "\n",
      "Elapsed 353.2467 s, Epoch 2,  Iteration 600, loss = 0.2340\n",
      "Checking accuracy on validation set\n",
      "Got 928 / 1000 correct (92.80)\n",
      "\n",
      "Elapsed 369.7311 s, Epoch 2,  Iteration 700, loss = 0.3253\n",
      "Checking accuracy on validation set\n",
      "Got 931 / 1000 correct (93.10)\n",
      "\n",
      "Elapsed 380.9944 s, Epoch 3,  Iteration 0, loss = 0.1535\n",
      "Checking accuracy on validation set\n",
      "Got 942 / 1000 correct (94.20)\n",
      "\n",
      "Elapsed 397.5550 s, Epoch 3,  Iteration 100, loss = 0.1732\n",
      "Checking accuracy on validation set\n",
      "Got 923 / 1000 correct (92.30)\n",
      "\n",
      "Elapsed 414.0402 s, Epoch 3,  Iteration 200, loss = 0.1775\n",
      "Checking accuracy on validation set\n",
      "Got 944 / 1000 correct (94.40)\n",
      "\n",
      "Elapsed 430.5503 s, Epoch 3,  Iteration 300, loss = 0.0070\n",
      "Checking accuracy on validation set\n",
      "Got 948 / 1000 correct (94.80)\n",
      "\n",
      "Elapsed 447.0642 s, Epoch 3,  Iteration 400, loss = 0.1813\n",
      "Checking accuracy on validation set\n",
      "Got 896 / 1000 correct (89.60)\n",
      "\n",
      "Elapsed 463.5144 s, Epoch 3,  Iteration 500, loss = 0.2025\n",
      "Checking accuracy on validation set\n",
      "Got 946 / 1000 correct (94.60)\n",
      "\n",
      "Elapsed 480.0608 s, Epoch 3,  Iteration 600, loss = 0.0557\n",
      "Checking accuracy on validation set\n",
      "Got 956 / 1000 correct (95.60)\n",
      "\n",
      "Elapsed 496.5840 s, Epoch 3,  Iteration 700, loss = 0.0160\n",
      "Checking accuracy on validation set\n",
      "Got 944 / 1000 correct (94.40)\n",
      "\n",
      "Elapsed 507.9032 s, Epoch 4,  Iteration 0, loss = 0.0835\n",
      "Checking accuracy on validation set\n",
      "Got 954 / 1000 correct (95.40)\n",
      "\n",
      "Elapsed 524.3853 s, Epoch 4,  Iteration 100, loss = 0.0755\n",
      "Checking accuracy on validation set\n",
      "Got 937 / 1000 correct (93.70)\n",
      "\n",
      "Elapsed 540.9071 s, Epoch 4,  Iteration 200, loss = 0.0034\n",
      "Checking accuracy on validation set\n",
      "Got 941 / 1000 correct (94.10)\n",
      "\n",
      "Elapsed 557.4375 s, Epoch 4,  Iteration 300, loss = 0.3336\n",
      "Checking accuracy on validation set\n",
      "Got 930 / 1000 correct (93.00)\n",
      "\n",
      "Elapsed 573.9044 s, Epoch 4,  Iteration 400, loss = 0.4644\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "\n",
      "Elapsed 590.2892 s, Epoch 4,  Iteration 500, loss = 1.9986\n",
      "Checking accuracy on validation set\n",
      "Got 286 / 1000 correct (28.60)\n",
      "\n",
      "Elapsed 606.7013 s, Epoch 4,  Iteration 600, loss = 1.6823\n",
      "Checking accuracy on validation set\n",
      "Got 303 / 1000 correct (30.30)\n",
      "\n",
      "Elapsed 623.1542 s, Epoch 4,  Iteration 700, loss = 1.8117\n",
      "Checking accuracy on validation set\n",
      "Got 258 / 1000 correct (25.80)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train this model\n",
    "learning_rate = 2e-4\n",
    "\n",
    "optimizer = optim.Adam(params=FixedVGG19.parameters(), lr=learning_rate)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True)\n",
    "train_part34(FixedVGG19, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finetune Fixed VGG11 Accuracy:\n",
      "Checking accuracy on test set\n",
      "Got 8394 / 10000 correct (83.94)\n",
      "\n",
      "Floadt VGG11 Accuracy:\n",
      "Checking accuracy on test set\n",
      "Got 9206 / 10000 correct (92.06)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinetune Fixed VGG11 Accuracy:\")\n",
    "check_accuracy_part34(loader_test, FixedVGG19)\n",
    "print(\"\\nFloadt VGG11 Accuracy:\")\n",
    "check_accuracy_part34(loader_test, VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
