{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "#from utee import misc, quant, selector\n",
    "\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Load CIFAR-10\n",
    "NUM_TRAIN = 49000\n",
    "\n",
    "# The torchvision.transforms package provides tools for preprocessing data\n",
    "# and for performing data augmentation; here we set up a transform to\n",
    "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
    "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
    "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
    "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
    "# training set into train and val sets by passing a Sampler object to the\n",
    "# DataLoader telling how it should sample from the underlying Dataset.\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    t_begin = time.time()\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                t_elapse = time.time() - t_begin\n",
    "                print('Elapsed %.4f s, Epoch %d,  Iteration %d, loss = %.4f' % (t_elapse, e, t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.quantization import *\n",
    "\n",
    "#TODO: 1. Implement different function\n",
    "#      2. differentiate FC and CONV\n",
    "def quantize_weight(model, bits):\n",
    "    weight = model.state_dict()\n",
    "    for k, v in weight.items():\n",
    "        weight[k] = Quant.linear(v, bits)\n",
    "        #print(weight[k])\n",
    "    model.load_state_dict(weight)\n",
    "    return model\n",
    "\n",
    "#TODO: Add a dictionary for bit width and function.\n",
    "def train_fixed_weight(model, optimizer, epochs=1, bits=8):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    t_begin = time.time()\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Add quantization for weight\n",
    "            model = quantize_weight(model, bits)\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                t_elapse = time.time() - t_begin\n",
    "                print('Elapsed %.4f s, Epoch %d,  Iteration %d, loss = %.4f' % (t_elapse, e, t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features.0.weight', 'features.0.bias', 'features.2.weight', 'features.2.bias', 'features.5.weight', 'features.5.bias', 'features.7.weight', 'features.7.bias', 'features.10.weight', 'features.10.bias', 'features.12.weight', 'features.12.bias', 'features.14.weight', 'features.14.bias', 'features.16.weight', 'features.16.bias', 'features.19.weight', 'features.19.bias', 'features.21.weight', 'features.21.bias', 'features.23.weight', 'features.23.bias', 'features.25.weight', 'features.25.bias', 'features.28.weight', 'features.28.bias', 'features.30.weight', 'features.30.bias', 'features.32.weight', 'features.32.bias', 'features.34.weight', 'features.34.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Model.vgg_modules import *\n",
    "\n",
    "VGG19 = vgg19()\n",
    "VGG19.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../pretrain_model/model_best.pth.tar'\n",
    "VGG19.features = torch.nn.DataParallel(VGG19.features)\n",
    "VGG19.cuda()\n",
    "checkpoint = torch.load(PATH)\n",
    "start_epoch = checkpoint['epoch']\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "#print(VGG19.state_dict().keys())\n",
    "#print(checkpoint['state_dict'].keys())\n",
    "VGG19.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.Fixedvgg import *\n",
    "\n",
    "exp_bit = 16\n",
    "\n",
    "FixedVGG19 = fixed_vgg19(bits=exp_bit)\n",
    "FixedVGG19\n",
    "\n",
    "PATH = '../pretrain_model/model_best.pth.tar'\n",
    "FixedVGG19.features = torch.nn.DataParallel(FixedVGG19.features)\n",
    "FixedVGG19.cuda()\n",
    "checkpoint = torch.load(PATH)\n",
    "start_epoch = checkpoint['epoch']\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "#print(VGG19.state_dict().keys())\n",
    "#print(checkpoint['state_dict'].keys())\n",
    "FixedVGG19.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "FixedVGG19 = quantize_weight(FixedVGG19, exp_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed VGG19 Accuracy:\n",
      "Checking accuracy on test set\n",
      "Got 9205 / 10000 correct (92.05)\n",
      "\n",
      "Float VGG19 Accuracy:\n",
      "Checking accuracy on test set\n",
      "Got 9206 / 10000 correct (92.06)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFixed VGG19 Accuracy:\")\n",
    "check_accuracy_part34(loader_test, FixedVGG19)\n",
    "print(\"\\nFloat VGG19 Accuracy:\")\n",
    "check_accuracy_part34(loader_test, VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed 0.0596 s, Epoch 0,  Iteration 0, loss = 0.0008\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 6.2508 s, Epoch 0,  Iteration 100, loss = 0.0011\n",
      "Checking accuracy on validation set\n",
      "Got 997 / 1000 correct (99.70)\n",
      "\n",
      "Elapsed 12.4009 s, Epoch 0,  Iteration 200, loss = 0.0069\n",
      "Checking accuracy on validation set\n",
      "Got 998 / 1000 correct (99.80)\n",
      "\n",
      "Elapsed 18.5653 s, Epoch 0,  Iteration 300, loss = 0.0069\n",
      "Checking accuracy on validation set\n",
      "Got 997 / 1000 correct (99.70)\n",
      "\n",
      "Elapsed 24.7219 s, Epoch 0,  Iteration 400, loss = 0.0007\n",
      "Checking accuracy on validation set\n",
      "Got 977 / 1000 correct (97.70)\n",
      "\n",
      "Elapsed 30.8803 s, Epoch 0,  Iteration 500, loss = 0.0010\n",
      "Checking accuracy on validation set\n",
      "Got 998 / 1000 correct (99.80)\n",
      "\n",
      "Elapsed 37.0349 s, Epoch 0,  Iteration 600, loss = 0.0552\n",
      "Checking accuracy on validation set\n",
      "Got 995 / 1000 correct (99.50)\n",
      "\n",
      "Elapsed 43.2028 s, Epoch 0,  Iteration 700, loss = 0.0002\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 47.3502 s, Epoch 1,  Iteration 0, loss = 0.0003\n",
      "Checking accuracy on validation set\n",
      "Got 997 / 1000 correct (99.70)\n",
      "\n",
      "Elapsed 53.5113 s, Epoch 1,  Iteration 100, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 999 / 1000 correct (99.90)\n",
      "\n",
      "Elapsed 59.6656 s, Epoch 1,  Iteration 200, loss = 0.0071\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 65.8369 s, Epoch 1,  Iteration 300, loss = 0.0084\n",
      "Checking accuracy on validation set\n",
      "Got 993 / 1000 correct (99.30)\n",
      "\n",
      "Elapsed 72.0318 s, Epoch 1,  Iteration 400, loss = 0.0010\n",
      "Checking accuracy on validation set\n",
      "Got 994 / 1000 correct (99.40)\n",
      "\n",
      "Elapsed 78.1990 s, Epoch 1,  Iteration 500, loss = 0.0022\n",
      "Checking accuracy on validation set\n",
      "Got 993 / 1000 correct (99.30)\n",
      "\n",
      "Elapsed 84.3759 s, Epoch 1,  Iteration 600, loss = 0.0134\n",
      "Checking accuracy on validation set\n",
      "Got 998 / 1000 correct (99.80)\n",
      "\n",
      "Elapsed 90.5459 s, Epoch 1,  Iteration 700, loss = 0.0006\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 94.7035 s, Epoch 2,  Iteration 0, loss = 0.0002\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 100.8764 s, Epoch 2,  Iteration 100, loss = 0.0003\n",
      "Checking accuracy on validation set\n",
      "Got 992 / 1000 correct (99.20)\n",
      "\n",
      "Elapsed 107.0383 s, Epoch 2,  Iteration 200, loss = 0.0075\n",
      "Checking accuracy on validation set\n",
      "Got 992 / 1000 correct (99.20)\n",
      "\n",
      "Elapsed 113.1977 s, Epoch 2,  Iteration 300, loss = 0.0006\n",
      "Checking accuracy on validation set\n",
      "Got 997 / 1000 correct (99.70)\n",
      "\n",
      "Elapsed 119.3676 s, Epoch 2,  Iteration 400, loss = 0.0072\n",
      "Checking accuracy on validation set\n",
      "Got 993 / 1000 correct (99.30)\n",
      "\n",
      "Elapsed 125.5365 s, Epoch 2,  Iteration 500, loss = 0.0014\n",
      "Checking accuracy on validation set\n",
      "Got 997 / 1000 correct (99.70)\n",
      "\n",
      "Elapsed 131.7144 s, Epoch 2,  Iteration 600, loss = 0.0021\n",
      "Checking accuracy on validation set\n",
      "Got 991 / 1000 correct (99.10)\n",
      "\n",
      "Elapsed 137.8868 s, Epoch 2,  Iteration 700, loss = 0.0065\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 142.0468 s, Epoch 3,  Iteration 0, loss = 0.0011\n",
      "Checking accuracy on validation set\n",
      "Got 989 / 1000 correct (98.90)\n",
      "\n",
      "Elapsed 148.2139 s, Epoch 3,  Iteration 100, loss = 0.0004\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 154.3759 s, Epoch 3,  Iteration 200, loss = 0.1182\n",
      "Checking accuracy on validation set\n",
      "Got 988 / 1000 correct (98.80)\n",
      "\n",
      "Elapsed 160.5392 s, Epoch 3,  Iteration 300, loss = 0.0030\n",
      "Checking accuracy on validation set\n",
      "Got 995 / 1000 correct (99.50)\n",
      "\n",
      "Elapsed 166.7188 s, Epoch 3,  Iteration 400, loss = 0.0005\n",
      "Checking accuracy on validation set\n",
      "Got 998 / 1000 correct (99.80)\n",
      "\n",
      "Elapsed 172.8977 s, Epoch 3,  Iteration 500, loss = 0.0007\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 179.1449 s, Epoch 3,  Iteration 600, loss = 0.0104\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 185.3131 s, Epoch 3,  Iteration 700, loss = 0.0016\n",
      "Checking accuracy on validation set\n",
      "Got 989 / 1000 correct (98.90)\n",
      "\n",
      "Elapsed 189.4667 s, Epoch 4,  Iteration 0, loss = 0.0029\n",
      "Checking accuracy on validation set\n",
      "Got 995 / 1000 correct (99.50)\n",
      "\n",
      "Elapsed 195.6624 s, Epoch 4,  Iteration 100, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 201.8083 s, Epoch 4,  Iteration 200, loss = 0.0048\n",
      "Checking accuracy on validation set\n",
      "Got 988 / 1000 correct (98.80)\n",
      "\n",
      "Elapsed 207.9577 s, Epoch 4,  Iteration 300, loss = 0.0036\n",
      "Checking accuracy on validation set\n",
      "Got 994 / 1000 correct (99.40)\n",
      "\n",
      "Elapsed 214.1036 s, Epoch 4,  Iteration 400, loss = 0.0291\n",
      "Checking accuracy on validation set\n",
      "Got 997 / 1000 correct (99.70)\n",
      "\n",
      "Elapsed 220.2502 s, Epoch 4,  Iteration 500, loss = 0.0058\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 226.4076 s, Epoch 4,  Iteration 600, loss = 0.0009\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 232.5656 s, Epoch 4,  Iteration 700, loss = 0.0008\n",
      "Checking accuracy on validation set\n",
      "Got 995 / 1000 correct (99.50)\n",
      "\n",
      "Elapsed 236.7103 s, Epoch 5,  Iteration 0, loss = 0.0115\n",
      "Checking accuracy on validation set\n",
      "Got 993 / 1000 correct (99.30)\n",
      "\n",
      "Elapsed 242.8559 s, Epoch 5,  Iteration 100, loss = 0.0950\n",
      "Checking accuracy on validation set\n",
      "Got 997 / 1000 correct (99.70)\n",
      "\n",
      "Elapsed 249.0056 s, Epoch 5,  Iteration 200, loss = 0.0012\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 255.1549 s, Epoch 5,  Iteration 300, loss = 0.0026\n",
      "Checking accuracy on validation set\n",
      "Got 994 / 1000 correct (99.40)\n",
      "\n",
      "Elapsed 261.2960 s, Epoch 5,  Iteration 400, loss = 0.0037\n",
      "Checking accuracy on validation set\n",
      "Got 993 / 1000 correct (99.30)\n",
      "\n",
      "Elapsed 267.4446 s, Epoch 5,  Iteration 500, loss = 0.0023\n",
      "Checking accuracy on validation set\n",
      "Got 992 / 1000 correct (99.20)\n",
      "\n",
      "Elapsed 273.5944 s, Epoch 5,  Iteration 600, loss = 0.0200\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 279.7308 s, Epoch 5,  Iteration 700, loss = 0.0950\n",
      "Checking accuracy on validation set\n",
      "Got 979 / 1000 correct (97.90)\n",
      "\n",
      "Elapsed 283.8817 s, Epoch 6,  Iteration 0, loss = 0.0637\n",
      "Checking accuracy on validation set\n",
      "Got 991 / 1000 correct (99.10)\n",
      "\n",
      "Elapsed 290.0376 s, Epoch 6,  Iteration 100, loss = 0.0002\n",
      "Checking accuracy on validation set\n",
      "Got 989 / 1000 correct (98.90)\n",
      "\n",
      "Elapsed 296.1788 s, Epoch 6,  Iteration 200, loss = 0.0003\n",
      "Checking accuracy on validation set\n",
      "Got 997 / 1000 correct (99.70)\n",
      "\n",
      "Elapsed 302.3165 s, Epoch 6,  Iteration 300, loss = 0.0169\n",
      "Checking accuracy on validation set\n",
      "Got 999 / 1000 correct (99.90)\n",
      "\n",
      "Elapsed 308.4702 s, Epoch 6,  Iteration 400, loss = 0.0002\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 314.6067 s, Epoch 6,  Iteration 500, loss = 0.0062\n",
      "Checking accuracy on validation set\n",
      "Got 992 / 1000 correct (99.20)\n",
      "\n",
      "Elapsed 320.7480 s, Epoch 6,  Iteration 600, loss = 0.0041\n",
      "Checking accuracy on validation set\n",
      "Got 995 / 1000 correct (99.50)\n",
      "\n",
      "Elapsed 326.8827 s, Epoch 6,  Iteration 700, loss = 0.0007\n",
      "Checking accuracy on validation set\n",
      "Got 991 / 1000 correct (99.10)\n",
      "\n",
      "Elapsed 331.0649 s, Epoch 7,  Iteration 0, loss = 0.0005\n",
      "Checking accuracy on validation set\n",
      "Got 992 / 1000 correct (99.20)\n",
      "\n",
      "Elapsed 337.2628 s, Epoch 7,  Iteration 100, loss = 0.0004\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 343.4092 s, Epoch 7,  Iteration 200, loss = 0.0003\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 349.5652 s, Epoch 7,  Iteration 300, loss = 0.0004\n",
      "Checking accuracy on validation set\n",
      "Got 997 / 1000 correct (99.70)\n",
      "\n",
      "Elapsed 355.7240 s, Epoch 7,  Iteration 400, loss = 0.0001\n",
      "Checking accuracy on validation set\n",
      "Got 998 / 1000 correct (99.80)\n",
      "\n",
      "Elapsed 361.8817 s, Epoch 7,  Iteration 500, loss = 0.0003\n",
      "Checking accuracy on validation set\n",
      "Got 997 / 1000 correct (99.70)\n",
      "\n",
      "Elapsed 368.0376 s, Epoch 7,  Iteration 600, loss = 0.0004\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 374.1853 s, Epoch 7,  Iteration 700, loss = 0.0011\n",
      "Checking accuracy on validation set\n",
      "Got 994 / 1000 correct (99.40)\n",
      "\n",
      "Elapsed 378.3414 s, Epoch 8,  Iteration 0, loss = 0.0020\n",
      "Checking accuracy on validation set\n",
      "Got 991 / 1000 correct (99.10)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed 384.4951 s, Epoch 8,  Iteration 100, loss = 0.0006\n",
      "Checking accuracy on validation set\n",
      "Got 993 / 1000 correct (99.30)\n",
      "\n",
      "Elapsed 390.6342 s, Epoch 8,  Iteration 200, loss = 0.0023\n",
      "Checking accuracy on validation set\n",
      "Got 988 / 1000 correct (98.80)\n",
      "\n",
      "Elapsed 396.8240 s, Epoch 8,  Iteration 300, loss = 0.0070\n",
      "Checking accuracy on validation set\n",
      "Got 990 / 1000 correct (99.00)\n",
      "\n",
      "Elapsed 403.0384 s, Epoch 8,  Iteration 400, loss = 0.0415\n",
      "Checking accuracy on validation set\n",
      "Got 989 / 1000 correct (98.90)\n",
      "\n",
      "Elapsed 409.2592 s, Epoch 8,  Iteration 500, loss = 0.0023\n",
      "Checking accuracy on validation set\n",
      "Got 987 / 1000 correct (98.70)\n",
      "\n",
      "Elapsed 415.4775 s, Epoch 8,  Iteration 600, loss = 0.0006\n",
      "Checking accuracy on validation set\n",
      "Got 995 / 1000 correct (99.50)\n",
      "\n",
      "Elapsed 421.7002 s, Epoch 8,  Iteration 700, loss = 0.1264\n",
      "Checking accuracy on validation set\n",
      "Got 992 / 1000 correct (99.20)\n",
      "\n",
      "Elapsed 425.9076 s, Epoch 9,  Iteration 0, loss = 0.0013\n",
      "Checking accuracy on validation set\n",
      "Got 993 / 1000 correct (99.30)\n",
      "\n",
      "Elapsed 432.1360 s, Epoch 9,  Iteration 100, loss = 0.0004\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 438.2912 s, Epoch 9,  Iteration 200, loss = 0.0009\n",
      "Checking accuracy on validation set\n",
      "Got 996 / 1000 correct (99.60)\n",
      "\n",
      "Elapsed 444.4483 s, Epoch 9,  Iteration 300, loss = 0.0759\n",
      "Checking accuracy on validation set\n",
      "Got 993 / 1000 correct (99.30)\n",
      "\n",
      "Elapsed 450.6025 s, Epoch 9,  Iteration 400, loss = 0.0007\n",
      "Checking accuracy on validation set\n",
      "Got 995 / 1000 correct (99.50)\n",
      "\n",
      "Elapsed 456.7462 s, Epoch 9,  Iteration 500, loss = 0.0017\n",
      "Checking accuracy on validation set\n",
      "Got 999 / 1000 correct (99.90)\n",
      "\n",
      "Elapsed 462.8929 s, Epoch 9,  Iteration 600, loss = 0.0058\n",
      "Checking accuracy on validation set\n",
      "Got 989 / 1000 correct (98.90)\n",
      "\n",
      "Elapsed 469.0482 s, Epoch 9,  Iteration 700, loss = 0.0003\n",
      "Checking accuracy on validation set\n",
      "Got 992 / 1000 correct (99.20)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train this model\n",
    "learning_rate = 4e-5\n",
    "\n",
    "optimizer = optim.Adam(params=FixedVGG19.parameters(), lr=learning_rate)\n",
    "#optimizer = optim.SGD(FixedVGG19.parameters(), lr=learning_rate,momentum=0.9, nesterov=True)\n",
    "train_fixed_weight(FixedVGG19, optimizer, epochs=10, bits=exp_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Float VGG19 Accuracy:\n",
      "Checking accuracy on test set\n",
      "Got 9206 / 10000 correct (92.06)\n",
      "\n",
      "Finetune Fixed VGG19 Accuracy:\n",
      "Checking accuracy on test set\n",
      "Got 9203 / 10000 correct (92.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFloat VGG19 Accuracy:\")\n",
    "check_accuracy_part34(loader_test, VGG19)\n",
    "print(\"\\nFinetune Fixed VGG19 Accuracy:\")\n",
    "check_accuracy_part34(loader_test, FixedVGG19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
